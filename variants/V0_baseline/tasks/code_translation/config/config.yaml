# Configuration for code translation task
task: code_translation

# Dummy mode configuration for testing
dummy_mode:
  enabled: false
  sample_size: 10
  num_epochs: 1
  batch_size: 4
  max_length: 128

model:
  name: Qwen/Qwen2.5-Coder-0.5B
  type: causal_lm
  precision: fp32
  device: auto

# Data stage configurations
data:
  batch_size: 8
  shuffle: true
  num_workers: 2
  pin_memory: true
  max_length: 512
  truncation: true
  padding: max_length

# Training stage configurations
training:
  learning_rate: 1e-5
  num_epochs: 3
  optimizer: adamw
  scheduler: linear
  gradient_accumulation_steps: 4
  weight_decay: 0.01
  warmup_ratio: 0.1
  max_grad_norm: 1.0
  logging_steps: 100
  save_steps: 500
  eval_steps: 500
  evaluation_strategy: steps
  save_strategy: steps
  load_best_model_at_end: true
  metric_for_best_model: loss
  lr_scheduler_type: linear
  batch_size: 8
  eval_batch_size: 8
  gradient_checkpointing: true
  fp16: false
  bf16: false

# Inference stage configurations
inference:
  batch_size: 8
  num_workers: 2
  pin_memory: true
  max_length: 512
  num_beams: 4
  temperature: 1.0
  top_p: 0.95
  do_sample: false

# Energy monitoring configuration
energy:
  co2_conversion_factor: 0.233
  monitor_gpu: true
  monitor_cpu: true
  monitor_memory: true
  save_traces: true
  trace_interval: 1.0 