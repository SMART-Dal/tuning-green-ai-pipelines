# Configuration for code translation task
task: code_translation

# Dummy mode configuration for testing
dummy_mode:
  enabled: true  # Set to true to use dummy configurations for testing
  sample_size: 100  # Number of examples to use in dummy mode
  num_epochs: 1
  batch_size: 8
  max_length: 128

model:
  name: Qwen/Qwen2.5-Coder-0.5B
  type: causal_lm
  precision: fp32
  device: auto

# Data stage configurations
data:
  versions:
    default:
      batch_size: 32
      shuffle: true
      num_workers: 4
      pin_memory: true
      cache_dir: ${oc.env:PROJECT_ROOT}/cache
      use_cache: true
      max_length: 512
      truncation: true
      padding: max_length
    dummy:  # Dummy version for quick testing
      batch_size: 8
      shuffle: true
      num_workers: 2
      pin_memory: true
      cache_dir: ${oc.env:PROJECT_ROOT}/cache
      use_cache: false
      max_length: 128
      truncation: true
      padding: max_length
    large_batch:
      batch_size: 64
      shuffle: true
      num_workers: 8
      pin_memory: true
      cache_dir: ${oc.env:PROJECT_ROOT}/cache
      use_cache: true
    small_batch:
      batch_size: 16
      shuffle: true
      num_workers: 2
      pin_memory: true
      cache_dir: ${oc.env:PROJECT_ROOT}/cache
      use_cache: true

# Architecture stage configurations
architecture:
  versions:
    default:
      precision: fp32
      device: auto
      load_in_8bit: false
      load_in_4bit: false
      bnb_4bit_compute_dtype: null
      bnb_4bit_quant_type: null
    fp16:
      precision: fp16
      device: auto
    int8:
      precision: int8
      device: auto

# Training stage configurations
training:
  versions:
    default:
      learning_rate: 1e-5  # Lower learning rate for fine-tuning
      num_epochs: 1
      optimizer: adamw
      scheduler: linear
      gradient_accumulation_steps: 1
      weight_decay: 0.01
      warmup_ratio: 0.1  # Added warmup for fine-tuning
      max_grad_norm: 1.0
      logging_steps: 100
      save_steps: 500
      eval_steps: 500
      evaluation_strategy: steps
      save_strategy: steps
      load_best_model_at_end: true
      metric_for_best_model: loss
      lr_scheduler_type: linear
      per_device_train_batch_size: 32
      per_device_eval_batch_size: 32
      gradient_checkpointing: true  # Enable gradient checkpointing for memory efficiency
      fp16: false  # Mixed precision training
      bf16: false  # BFloat16 training
    dummy:  # Dummy version for quick testing
      learning_rate: 1e-4
      num_epochs: 1
      optimizer: adamw
      scheduler: linear
      gradient_accumulation_steps: 1
      weight_decay: 0.01
      warmup_ratio: 0.1
      max_grad_norm: 1.0
      logging_steps: 10
      save_steps: 50
      eval_steps: 50
      evaluation_strategy: steps
      save_strategy: steps
      load_best_model_at_end: true
      metric_for_best_model: loss
      lr_scheduler_type: linear
      per_device_train_batch_size: 8
      per_device_eval_batch_size: 8
      gradient_checkpointing: false
      fp16: false
      bf16: false
    high_lr:
      learning_rate: 5e-5
      num_epochs: 3
      optimizer: adamw
      scheduler: cosine
      gradient_accumulation_steps: 1
      warmup_ratio: 0.1
      gradient_checkpointing: true
    gradient_accumulation:
      learning_rate: 1e-5
      num_epochs: 3
      optimizer: adamw
      scheduler: linear
      gradient_accumulation_steps: 4
      warmup_ratio: 0.1
      gradient_checkpointing: true

# Inference stage configurations
inference:
  versions:
    default:
      batch_size: 32
      num_workers: 4
      pin_memory: true
      max_length: 512
      num_beams: 4
      temperature: 1.0
      top_p: 0.95
      do_sample: false
    fast:
      batch_size: 64
      num_workers: 8
      pin_memory: true
    accurate:
      batch_size: 16
      num_workers: 2
      pin_memory: true

# System stage configurations
system:
  versions:
    default:
      monitor_duration: 60
      sample_interval: 1
      power_limit: null
      memory_limit: null
      cpu_limit: null
    quick:
      monitor_duration: 30
      sample_interval: 2
    detailed:
      monitor_duration: 120
      sample_interval: 0.5

# Energy monitoring configuration
energy:
  co2_conversion_factor: 0.233
  monitor_gpu: true
  monitor_cpu: true
  monitor_memory: true
  save_traces: true
  trace_interval: 1.0 