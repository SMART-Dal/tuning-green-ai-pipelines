=== GREEN AI PIPELINE ANALYSIS REPORT ===

1. OVERALL STATISTICS
===================
Total number of variants analyzed: 31
Baseline variant: v0_baseline

2. INDIVIDUAL VARIANT ANALYSIS
===========================

Variant: v0_baseline
--------------------
Total Energy: 0.512333 kWh (±0.000000)
Runtime: 7918.790106 s (±0.000000)
F1 Score: 0.993527 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: 0.000000%
Time: 0.000000%
F1 Score: 0.000000%


Variant: v1_gradient_checkpointing
----------------------------------
Total Energy: 0.669636 kWh (±0.000000)
Runtime: 10443.632337 s (±0.000000)
F1 Score: 0.993233 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: 30.703058%
Time: 31.884192%
F1 Score: -0.029649%


Variant: v2_lora_peft
---------------------
Total Energy: 0.075271 kWh (±0.000456)
Runtime: 1696.330459 s (±7.226672)
F1 Score: 0.953679 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -85.308286%
Time: -78.578414%
F1 Score: -4.010812%


Variant: v3_quantization
------------------------
Total Energy: 0.485841 kWh (±0.000828)
Runtime: 11633.018217 s (±4.644198)
F1 Score: 0.992947 (±0.000402)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -5.170880%
Time: 46.903985%
F1 Score: -0.058388%


Variant: v4_tokenizer
---------------------
Total Energy: 0.512864 kWh (±0.000000)
Runtime: 7931.637845 s (±0.000000)
F1 Score: 0.994608 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: 0.103569%
Time: 0.162244%
F1 Score: 0.108726%


Variant: v5_power_limit_100w
----------------------------
Total Energy: 0.648044 kWh (±0.000000)
Runtime: 20506.253786 s (±0.000000)
F1 Score: 0.993079 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: 26.488781%
Time: 158.956905%
F1 Score: -0.045121%


Variant: v6_optimizer
---------------------
Total Energy: 0.488799 kWh (±0.000000)
Runtime: 7632.979717 s (±0.000000)
F1 Score: 0.993560 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -4.593609%
Time: -3.609268%
F1 Score: 0.003277%


Variant: v7_f16
---------------
Total Energy: 0.407268 kWh (±0.000000)
Runtime: 6606.288716 s (±0.000000)
F1 Score: 0.993385 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -20.507340%
Time: -16.574519%
F1 Score: -0.014334%


Variant: v8_sequence_length_trimming
------------------------------------
Total Energy: 0.273417 kWh (±0.000000)
Runtime: 4442.942382 s (±0.000000)
F1 Score: 0.989770 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -46.633092%
Time: -43.893672%
F1 Score: -0.378230%


Variant: v9_inference_engine
----------------------------
Total Energy: 0.470787 kWh (±0.000000)
Runtime: 7445.584190 s (±0.000000)
F1 Score: 0.991698 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -8.109200%
Time: -5.975735%
F1 Score: -0.184121%


Variant: v10_dataloader_pin_memory
----------------------------------
Total Energy: 0.407903 kWh (±0.000000)
Runtime: 6642.134608 s (±0.000000)
F1 Score: 0.993369 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -20.383342%
Time: -16.121850%
F1 Score: -0.015939%


Variant: v11_torch_compile
--------------------------
Total Energy: 0.315396 kWh (±0.000000)
Runtime: 4757.085481 s (±0.000000)
F1 Score: 0.993430 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -38.439408%
Time: -39.926612%
F1 Score: -0.009760%


Variant: v12_attention
----------------------
Total Energy: 0.375107 kWh (±0.000000)
Runtime: 5771.804353 s (±0.000000)
F1 Score: 0.993910 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -26.784517%
Time: -27.112548%
F1 Score: 0.038463%


Variant: v13_layer_pruning_4_top
--------------------------------
Total Energy: 0.435380 kWh (±0.000000)
Runtime: 6606.560527 s (±0.000000)
F1 Score: 0.994525 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -15.020211%
Time: -16.571087%
F1 Score: 0.100420%


Variant: v14_layer_pruning_4_bottom
-----------------------------------
Total Energy: 0.434701 kWh (±0.000000)
Runtime: 6595.396425 s (±0.000000)
F1 Score: 0.992534 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -15.152789%
Time: -16.712069%
F1 Score: -0.100011%


Variant: v15_layer_pruning_8_top
--------------------------------
Total Energy: 0.339213 kWh (±0.000000)
Runtime: 5270.642069 s (±0.000000)
F1 Score: 0.994244 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -33.790669%
Time: -33.441321%
F1 Score: 0.072170%


Variant: v16_layer_pruning_8_bottom
-----------------------------------
Total Energy: 0.339393 kWh (±0.000000)
Runtime: 5266.671282 s (±0.000000)
F1 Score: 0.992453 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -33.755506%
Time: -33.491465%
F1 Score: -0.108134%


Variant: v17_layer_pruning_12_top
---------------------------------
Total Energy: 0.261783 kWh (±0.000000)
Runtime: 3936.835652 s (±0.000000)
F1 Score: 0.994576 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -48.903815%
Time: -50.284884%
F1 Score: 0.105508%


Variant: v18_layer_pruning_12_bottom
------------------------------------
Total Energy: 0.262498 kWh (±0.000000)
Runtime: 3953.074674 s (±0.000000)
F1 Score: 0.993146 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -48.764141%
Time: -50.079815%
F1 Score: -0.038422%


Variant: v19_layer_pruning_16_top
---------------------------------
Total Energy: 0.162196 kWh (±0.000000)
Runtime: 2549.173860 s (±0.000000)
F1 Score: 0.994578 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -68.341736%
Time: -67.808544%
F1 Score: 0.105760%


Variant: v20_layer_pruning_16_bottom
------------------------------------
Total Energy: 0.161760 kWh (±0.000000)
Runtime: 2538.462434 s (±0.000000)
F1 Score: 0.994042 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -68.426800%
Time: -67.943810%
F1 Score: 0.051741%


Variant: v21_layer_pruning_20_top
---------------------------------
Total Energy: 0.079047 kWh (±0.000234)
Runtime: 1143.029340 s (±3.311950)
F1 Score: 0.992763 (±0.000250)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -84.571236%
Time: -85.565606%
F1 Score: -0.076992%


Variant: v22_layer_pruning_20_bottom
------------------------------------
Total Energy: 0.079279 kWh (±0.000354)
Runtime: 1143.431485 s (±0.072823)
F1 Score: 0.994307 (±0.000157)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -84.525983%
Time: -85.560528%
F1 Score: 0.078507%


Variant: v23_attention_plus_pin_memory_plus_optimizer_plus_gradient_accumulation
--------------------------------------------------------------------------------
Total Energy: 0.446365 kWh (±0.000000)
Runtime: 6511.576854 s (±0.000000)
F1 Score: 0.994586 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -12.876122%
Time: -17.770559%
F1 Score: 0.106578%


Variant: v24_inference_engine_plus_grad_cpting_plus_lora_plus_fp16
------------------------------------------------------------------
Total Energy: 0.068847 kWh (±0.000000)
Runtime: 1692.470310 s (±0.000000)
F1 Score: 0.953037 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -86.562014%
Time: -78.627160%
F1 Score: -4.075468%


Variant: v25_gradient_accumulation_plus_fp16_plus_checkpointing
---------------------------------------------------------------
Total Energy: 0.688727 kWh (±0.000000)
Runtime: 10279.575371 s (±0.000000)
F1 Score: 0.994696 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: 34.429508%
Time: 29.812449%
F1 Score: 0.117584%


Variant: v26_pruning_plus_seq_lngth_plus_torch_compile
------------------------------------------------------
Total Energy: 0.098557 kWh (±0.000000)
Runtime: 1447.236235 s (±0.000000)
F1 Score: 0.990945 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -80.763104%
Time: -81.724023%
F1 Score: -0.259878%


Variant: v27_torch_compile_plus_fp16
------------------------------------
Total Energy: 0.276725 kWh (±0.000000)
Runtime: 4093.449516 s (±0.000000)
F1 Score: 0.993811 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -45.987291%
Time: -48.307135%
F1 Score: 0.028528%


Variant: v28_pruning_plus_torch_compile_plus_fp16
-------------------------------------------------
Total Energy: 0.134768 kWh (±0.000000)
Runtime: 2066.457309 s (±0.000000)
F1 Score: 0.992874 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -73.695234%
Time: -73.904381%
F1 Score: -0.065732%


Variant: v29_attention_plus_pin_memory_plus_optimizer
-----------------------------------------------------
Total Energy: 0.355955 kWh (±0.000000)
Runtime: 5535.841995 s (±0.000000)
F1 Score: 0.993524 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -30.522851%
Time: -30.092326%
F1 Score: -0.000331%


Variant: v30_optimal
--------------------
Total Energy: 0.027455 kWh (±0.000000)
Runtime: 537.160865 s (±0.000000)
F1 Score: 0.953679 (±0.000000)
Accuracy: 0.000000
GPU Utilization: 0.000000%
GPU Memory Utilization: 0.000000%
Peak Memory: 0.000000 GB

Differences from baseline:
Energy: -94.641181%
Time: -93.216630%
F1 Score: -4.010812%

3. COMBINED VARIANTS ANALYSIS
===========================

Combined Variant: v27_torch_compile_plus_fp16
--------------------------------------------
Description: Combines torch compile and FP16 precision

Combined Variant Metrics:
Total Energy: 0.276725 kWh
Runtime: 4093.449516 s
F1 Score: 0.993811
Energy Savings vs Baseline: -45.987291%
Time Savings vs Baseline: -48.307135%
F1 Impact vs Baseline: 0.028528%

Comparison with Individual Components:
---------------------------------

Component: v11_torch_compile
Energy Impact: -12.260901%
Time Impact: -13.950474%
F1 Score Impact: 0.000380
Interpretation:
- Energy efficient compared to v11_torch_compile
- Faster than v11_torch_compile
- Better F1 score than v11_torch_compile
Component V7_f16 not found in data

Overall Analysis:
----------------
Average Energy Impact: -12.260901%
Average Time Impact: -13.950474%
Average F1 Impact: 0.000380

Recommendation:
This combination is recommended as it improves both efficiency and performance

==================================================
4. STAGE-WISE ANALYSIS
=====================

Stage: load_dataset
-------------------
Average Energy: 0.000053 kWh
Std Dev: 0.000026 kWh
Min Energy: 0.000027 kWh
Max Energy: 0.000114 kWh
Average Duration: 3.127002 s
Duration Std Dev: 1.611370 s
Min Duration: 1.439471 s
Max Duration: 6.866096 s

Stage: tokenize_dataset
-----------------------
Average Energy: 0.000152 kWh
Std Dev: 0.000608 kWh
Min Energy: 0.000004 kWh
Max Energy: 0.003533 kWh
Average Duration: 4.927037 s
Duration Std Dev: 19.660691 s
Min Duration: 0.134016 s
Max Duration: 114.430325 s

Stage: load_model
-----------------
Average Energy: 0.000133 kWh
Std Dev: 0.000624 kWh
Min Energy: 0.000024 kWh
Max Energy: 0.003721 kWh
Average Duration: 4.130482 s
Duration Std Dev: 19.538134 s
Min Duration: 0.696562 s
Max Duration: 116.411741 s

Stage: train_model
------------------
Average Energy: 0.287809 kWh
Std Dev: 0.178955 kWh
Min Energy: 0.020151 kWh
Max Energy: 0.643630 kWh
Average Duration: 5079.730018 s
Duration Std Dev: 3873.002002 s
Min Duration: 352.615531 s
Max Duration: 19116.853700 s

Stage: save_model
-----------------
Average Energy: 0.000118 kWh
Std Dev: 0.000296 kWh
Min Energy: 0.000007 kWh
Max Energy: 0.001129 kWh
Average Duration: 2.719024 s
Duration Std Dev: 6.881746 s
Min Duration: 0.196417 s
Max Duration: 25.298802 s

Stage: evaluate_model
---------------------
Average Energy: 0.026441 kWh
Std Dev: 0.015301 kWh
Min Energy: 0.002478 kWh
Max Energy: 0.055553 kWh
Average Duration: 339.976090 s
Duration Std Dev: 253.441040 s
Min Duration: 37.779037 s
Max Duration: 1382.855488 s

Stage-wise Energy Distribution:
load_dataset: 0.000481%
tokenize_dataset: 0.001380%
load_model: 0.001207%
train_model: 2.612951%
save_model: 0.001071%
evaluate_model: 0.240052%

Stage-wise Time Distribution:
load_dataset: 0.001644%
tokenize_dataset: 0.002590%
load_model: 0.002172%
train_model: 2.670572%
save_model: 0.001429%
evaluate_model: 0.178736%

5. STATISTICAL ANALYSIS
=====================

Energy Consumption Statistics:
Mean: 0.332107 kWh
Median: 0.339393 kWh
Std Dev: 0.186696 kWh
Min: 0.027455 kWh
Max: 0.688727 kWh

Runtime Statistics:
Mean: 5632.113819 s
Median: 5270.642069 s
Std Dev: 4006.390805 s
Min: 537.160865 s
Max: 20506.253786 s

Evaluation Time Statistics:
Mean: 350.733988 s
Median: 340.627217 s
Std Dev: 253.976353 s
Min: 37.779037 s
Max: 1382.855488 s

F1 Score Statistics:
Mean: 0.989500
Median: 0.993385
Std Dev: 0.012040
Min: 0.953037
Max: 0.994696

6. BEST PERFORMERS
================

Most Energy Efficient: v30_optimal
Energy Savings: -94.641181%
F1 Impact: -4.010812%

Fastest Runtime: v30_optimal
Time Savings: -93.216630%
F1 Impact: -4.010812%

Fastest Evaluation: v30_optimal
Evaluation Time Savings: -92.689591%
F1 Impact: -4.010812%

Best F1 Score: v25_gradient_accumulation_plus_fp16_plus_checkpointing
F1 Score: 0.994696
Energy Impact: 34.429508%
Time Impact: 29.812449%

7. RECOMMENDATIONS
================

For Energy Efficiency:
- v30_optimal: -94.641181% energy savings, F1 impact: -4.010812%
- v24_inference_engine_plus_grad_cpting_plus_lora_plus_fp16: -86.562014% energy savings, F1 impact: -4.075468%
- v2_lora_peft: -85.308286% energy savings, F1 impact: -4.010812%

For Performance:
- v25_gradient_accumulation_plus_fp16_plus_checkpointing: F1 score 0.994696, Energy impact: 34.429508%
- v4_tokenizer: F1 score 0.994608, Energy impact: 0.103569%
- v23_attention_plus_pin_memory_plus_optimizer_plus_gradient_accumulation: F1 score 0.994586, Energy impact: -12.876122%

For Balanced Approach:
- v30_optimal: Energy 0.027455 kWh, F1: 0.953679
- v21_layer_pruning_20_top: Energy 0.079047 kWh, F1: 0.992763
- v22_layer_pruning_20_bottom: Energy 0.079279 kWh, F1: 0.994307
- v19_layer_pruning_16_top: Energy 0.162196 kWh, F1: 0.994578
- v23_attention_plus_pin_memory_plus_optimizer_plus_gradient_accumulation: Energy 0.446365 kWh, F1: 0.994586
- v4_tokenizer: Energy 0.512864 kWh, F1: 0.994608
- v25_gradient_accumulation_plus_fp16_plus_checkpointing: Energy 0.688727 kWh, F1: 0.994696
